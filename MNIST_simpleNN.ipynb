{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlowチュートリアル(シンプルなニューラルネットワークでMNISTデータを分類する)\n",
    "(参考　: TensorFlowではじめるDeep Learning実装入門)\n",
    "## 1. パッケージのインポート\n",
    "まずは種々のパッケージのインポートを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, unicode_literals\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNISTのデータの取得\n",
    "- 変数mnistには，MNISTの手書き数字の画像データを全てダウンロードし，格納している．\n",
    "- 変数train_imagesには学習データを，変数train_labelsには学習データの正解ラベルを格納している\n",
    "- (ちなみにバッチ数は50に設定し，ミニバッチ学習を行うものとする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#mnist全データを取得\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#学習データ&ラベルを取得\n",
    "train_images  , train_labels = mnist.train.next_batch(50)\n",
    "\n",
    "#テストデータの取得\n",
    "test_images = mnist.test.images\n",
    "#テストラベルを取得\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ニューラルネットワークの定義\n",
    "- 入力層→中間層→出力層の順に定義していく\n",
    "\n",
    "### 入力層の定義\n",
    "- 入力データは28x28の画像を１次元に変換したデータ（サイズは28×28=784）を用いる\n",
    "- 入力データは実行時に定義できるようにプレースホルダとして定義する(tf.placeholder)\n",
    "- データ数は実行時まで不明なので，'None'として格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力層の定義\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中間層の定義\n",
    "入力層のデータを伝播させる中間層を定義する\n",
    "- w_1 ... 「重み」を表す．\n",
    "- b_1 ... 「バイアス」を表す．\n",
    "- h_1 ... 「中間層からの出力」を表す．\n",
    "- 全体的には，「h_1 = w_1 * x + b_1」という式を構築している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = tf.Variable(tf.truncated_normal([784,64], stddev=0.1), name = 'w1')\n",
    "b_1 = tf.Variable(tf.zeros([64]), name = 'b1')\n",
    "h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力層の定義\n",
    "中間層から出力されたデータを伝播させる出力層を定義する\n",
    "- w_2 ... 「重み」を表す．\n",
    "- b_2 ... 「バイアス」を表す．\n",
    "- out ... 「出力層からの出力」を表す．\n",
    "- 全体的には，「out = w_2 * h_1 + b_2」という式を構築している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_2 = tf.Variable(tf.truncated_normal([64,10], stddev=0.1), name = 'w2')\n",
    "b_2 = tf.Variable(tf.zeros([10]), name = 'b2')\n",
    "out = tf.nn.softmax(tf.matmul(h_1,w_2) + b_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 誤差関数と訓練方法の定義\n",
    "学習に必要な誤差関数を定義する\n",
    "### 誤差関数\n",
    "誤差関数は出力結果と正解値の差を二乗したものの平均値を用いる(本来は扱われていない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#誤差関数に扱う正解値\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "#誤差関数\n",
    "loss = tf.reduce_mean(tf.square(y-out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練方法の定義\n",
    "訓練方法は最急降下法を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度の評価式の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(out , 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct , tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 , Accuracy :  0.15 \n",
      "Epoch : 20 , Accuracy :  0.18 \n",
      "Epoch : 30 , Accuracy :  0.23 \n",
      "Epoch : 40 , Accuracy :  0.27 \n",
      "Epoch : 50 , Accuracy :  0.32 \n",
      "Epoch : 60 , Accuracy :  0.36 \n",
      "Epoch : 70 , Accuracy :  0.40 \n",
      "Epoch : 80 , Accuracy :  0.44 \n",
      "Epoch : 90 , Accuracy :  0.47 \n",
      "Epoch : 100 , Accuracy :  0.51 \n",
      "Epoch : 110 , Accuracy :  0.53 \n",
      "Epoch : 120 , Accuracy :  0.58 \n",
      "Epoch : 130 , Accuracy :  0.60 \n",
      "Epoch : 140 , Accuracy :  0.63 \n",
      "Epoch : 150 , Accuracy :  0.64 \n",
      "Epoch : 160 , Accuracy :  0.65 \n",
      "Epoch : 170 , Accuracy :  0.68 \n",
      "Epoch : 180 , Accuracy :  0.70 \n",
      "Epoch : 190 , Accuracy :  0.71 \n",
      "Epoch : 200 , Accuracy :  0.72 \n",
      "Epoch : 210 , Accuracy :  0.73 \n",
      "Epoch : 220 , Accuracy :  0.74 \n",
      "Epoch : 230 , Accuracy :  0.75 \n",
      "Epoch : 240 , Accuracy :  0.77 \n",
      "Epoch : 250 , Accuracy :  0.78 \n",
      "Epoch : 260 , Accuracy :  0.78 \n",
      "Epoch : 270 , Accuracy :  0.79 \n",
      "Epoch : 280 , Accuracy :  0.80 \n",
      "Epoch : 290 , Accuracy :  0.81 \n",
      "Epoch : 300 , Accuracy :  0.81 \n",
      "Epoch : 310 , Accuracy :  0.82 \n",
      "Epoch : 320 , Accuracy :  0.82 \n",
      "Epoch : 330 , Accuracy :  0.83 \n",
      "Epoch : 340 , Accuracy :  0.83 \n",
      "Epoch : 350 , Accuracy :  0.83 \n",
      "Epoch : 360 , Accuracy :  0.84 \n",
      "Epoch : 370 , Accuracy :  0.84 \n",
      "Epoch : 380 , Accuracy :  0.85 \n",
      "Epoch : 390 , Accuracy :  0.84 \n",
      "Epoch : 400 , Accuracy :  0.85 \n",
      "Epoch : 410 , Accuracy :  0.85 \n",
      "Epoch : 420 , Accuracy :  0.85 \n",
      "Epoch : 430 , Accuracy :  0.85 \n",
      "Epoch : 440 , Accuracy :  0.85 \n",
      "Epoch : 450 , Accuracy :  0.85 \n",
      "Epoch : 460 , Accuracy :  0.85 \n",
      "Epoch : 470 , Accuracy :  0.86 \n",
      "Epoch : 480 , Accuracy :  0.86 \n",
      "Epoch : 490 , Accuracy :  0.86 \n",
      "Epoch : 500 , Accuracy :  0.87 \n",
      "Epoch : 510 , Accuracy :  0.87 \n",
      "Epoch : 520 , Accuracy :  0.86 \n",
      "Epoch : 530 , Accuracy :  0.87 \n",
      "Epoch : 540 , Accuracy :  0.87 \n",
      "Epoch : 550 , Accuracy :  0.87 \n",
      "Epoch : 560 , Accuracy :  0.87 \n",
      "Epoch : 570 , Accuracy :  0.87 \n",
      "Epoch : 580 , Accuracy :  0.87 \n",
      "Epoch : 590 , Accuracy :  0.87 \n",
      "Epoch : 600 , Accuracy :  0.88 \n",
      "Epoch : 610 , Accuracy :  0.88 \n",
      "Epoch : 620 , Accuracy :  0.87 \n",
      "Epoch : 630 , Accuracy :  0.88 \n",
      "Epoch : 640 , Accuracy :  0.88 \n",
      "Epoch : 650 , Accuracy :  0.87 \n",
      "Epoch : 660 , Accuracy :  0.88 \n",
      "Epoch : 670 , Accuracy :  0.88 \n",
      "Epoch : 680 , Accuracy :  0.88 \n",
      "Epoch : 690 , Accuracy :  0.88 \n",
      "Epoch : 700 , Accuracy :  0.88 \n",
      "Epoch : 710 , Accuracy :  0.88 \n",
      "Epoch : 720 , Accuracy :  0.88 \n",
      "Epoch : 730 , Accuracy :  0.88 \n",
      "Epoch : 740 , Accuracy :  0.88 \n",
      "Epoch : 750 , Accuracy :  0.88 \n",
      "Epoch : 760 , Accuracy :  0.88 \n",
      "Epoch : 770 , Accuracy :  0.89 \n",
      "Epoch : 780 , Accuracy :  0.89 \n",
      "Epoch : 790 , Accuracy :  0.89 \n",
      "Epoch : 800 , Accuracy :  0.89 \n",
      "Epoch : 810 , Accuracy :  0.89 \n",
      "Epoch : 820 , Accuracy :  0.89 \n",
      "Epoch : 830 , Accuracy :  0.89 \n",
      "Epoch : 840 , Accuracy :  0.89 \n",
      "Epoch : 850 , Accuracy :  0.89 \n",
      "Epoch : 860 , Accuracy :  0.89 \n",
      "Epoch : 870 , Accuracy :  0.89 \n",
      "Epoch : 880 , Accuracy :  0.89 \n",
      "Epoch : 890 , Accuracy :  0.89 \n",
      "Epoch : 900 , Accuracy :  0.89 \n",
      "Epoch : 910 , Accuracy :  0.89 \n",
      "Epoch : 920 , Accuracy :  0.89 \n",
      "Epoch : 930 , Accuracy :  0.89 \n",
      "Epoch : 940 , Accuracy :  0.89 \n",
      "Epoch : 950 , Accuracy :  0.89 \n",
      "Epoch : 960 , Accuracy :  0.89 \n",
      "Epoch : 970 , Accuracy :  0.89 \n",
      "Epoch : 980 , Accuracy :  0.90 \n",
      "Epoch : 990 , Accuracy :  0.90 \n"
     ]
    }
   ],
   "source": [
    "#初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(init)\n",
    "    \n",
    "    #テストデータの取得\n",
    "    test_images = mnist.test.images\n",
    "    #テストラベルを取得\n",
    "    test_labels = mnist.test.labels\n",
    "    \n",
    "    #1000回のエポック数（ステップ数）で学習を実行\n",
    "    for epoch in range(1,1000):\n",
    "        #バッチ数を50として学習データとラベルを取り出す\n",
    "        train_images, train_labels =mnist.train.next_batch(50)\n",
    "        #学習を行う\n",
    "        sess.run(train_step, feed_dict = {x:train_images , y:train_labels})\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            #10エポック毎に精度を算出\n",
    "            acc_val = sess.run(accuracy , feed_dict = {x:test_images , y:test_labels})\n",
    "            print ('Epoch : %d , Accuracy :  %.2f ' % (epoch , acc_val))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
